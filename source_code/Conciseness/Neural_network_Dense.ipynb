{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import utility as ut\n",
    "import features_final as f\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(filename,filenameWrite):\n",
    "    \n",
    "    features = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\",newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            #print len(row)\n",
    "            title = row[2]\n",
    "            description = row[6]\n",
    "            cleanedDescription = ut.cleanDescription(description)\n",
    "            #cleanedDescription = cleanText(cleanedDescription)\n",
    "            cleanedTitle = ut.cleanText(title, False)\n",
    "            \n",
    "            # normalize price\n",
    "            price = float(row[7])\n",
    "            country = row[0]\n",
    "            newPrice = ut.normalizePrice(price, country)\n",
    "            \n",
    "            cleanedRow = [row[0],row[1],cleanedTitle,row[3],row[4],row[5],cleanedDescription, newPrice,row[8]]\n",
    "            features.append(cleanedRow)\n",
    "\n",
    "    writer = csv.writer(open(filenameWrite, 'w',newline=''))\n",
    "    writer.writerows(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the text in the train data............\n"
     ]
    }
   ],
   "source": [
    "#Should be done only once\n",
    "\n",
    "print(\"Cleaning the text in the train data............\")\n",
    "clean('Data/training/data_train.csv','Data/training/data_train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word Vectors............\n",
      "Loaded Word Vectors.............\n"
     ]
    }
   ],
   "source": [
    "#Load the word vectors\n",
    "\n",
    "w2v_model = f.loadWordVectors('google_news_word_vectors/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Features............\n",
      "Features Computed............\n"
     ]
    }
   ],
   "source": [
    "#Pass the features that you want to test. The order of features are as given below\n",
    "#word2VecFlag \n",
    "#lengthAndBooleanFlag\n",
    "#tfidfLabelIntersectFlag\n",
    "#numericFlag\n",
    "#denseEntropySKUFlag\n",
    "\n",
    "\n",
    "print(\"Computing Features............\")\n",
    "X = f.extract_features(\"Data/training/data_train_clean.csv\",w2v_model,False,True,False,False,False)\n",
    "X_input = X.astype(np.float)\n",
    "\n",
    "print(\"Features Computed............\")\n",
    "\n",
    "y_input = np.loadtxt(\"data/training/conciseness_train.labels\", dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the features\n",
    "\n",
    "X_std = (X_input - X_input.min(axis=0)) / (X_input.max(axis=0) - X_input.min(axis=0))\n",
    "X_input = X_std\n",
    "X_input = X_input[:,~np.all(np.isnan(X_input), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pickle the files, load the pickled files\n",
    "#Use this only if you want to pickle the features and use it later, else don't run this cell\n",
    "\n",
    "import pickle\n",
    "\n",
    "#pickle.dump(X_input, open( \"X_input_numerical.p\", \"wb\" ))\n",
    "#pickle.dump(y_input, open( \"y_input_numerical.p\", \"wb\" ))\n",
    "\n",
    "#Load either the X_input_binary or X_input_numerical depending on the features to be tested\n",
    "#loaded_X_input = pickle.load( open( \"X_input_binary.p\", \"rb\" ) )\n",
    "#loaded_y_input = pickle.load( open( \"y_input_binary.p\", \"rb\" ) )\n",
    "\n",
    "#y_input = np.loadtxt(\"data/training/clarity_train.labels\", dtype=float)\n",
    "\n",
    "X_input = loaded_X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEEEP LEARNING!!!!!!!!!!!!\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.layers import LSTM\n",
    "\n",
    "#Using a 4-fold to get a good train-test split\n",
    "\n",
    "kFoldResults = ut.splitKFold(X_input,y_input,4)\n",
    "\n",
    "trainRMSE = []\n",
    "testRMSE = []\n",
    "trainF1 = []\n",
    "testF1 = []\n",
    "testPS = []\n",
    "testRAS = []\n",
    "testAcc = []\n",
    "testRecall = []\n",
    "testAvgPS = []\n",
    "\n",
    "for resultGenerator in kFoldResults:\n",
    "    \n",
    "    batch_size = 32\n",
    "    filters = 150\n",
    "    filter_sizes = [2,3,5]\n",
    "    hidden_dims1 = 200\n",
    "    hidden_dims2 = 100\n",
    "    num_epochs = 10\n",
    "    sgd = optimizers.SGD(lr=1.1)\n",
    "    model = Sequential()\n",
    "\n",
    "    #First Dense Layer\n",
    "    model.add(Dense(600,input_dim=X_input.shape[1],kernel_initializer=\"random_uniform\",activation=\"elu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #Second Dense Layer\n",
    "    model.add(Dense(300,kernel_initializer=\"random_uniform\",activation=\"elu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #Third Dense Layer\n",
    "    model.add(Dense(200,kernel_initializer=\"random_uniform\",activation=\"elu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #Fourth Dense Layer\n",
    "    model.add(Dense(100,kernel_initializer=\"random_uniform\",activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #Final Output Layer\n",
    "    model.add(Dense(1,kernel_initializer=\"random_uniform\",activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    trainIndices = resultGenerator[0]\n",
    "    testIndices = resultGenerator[1]\n",
    "    \n",
    "    X_train = list()\n",
    "    y_train=list()\n",
    "    X_test=list()\n",
    "    y_test=list()\n",
    "    \n",
    "    for trainRow in trainIndices:\n",
    "        X_train.append(X_input[trainRow])\n",
    "        y_train.append(y_input[trainRow])\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    \n",
    "    # Model training\n",
    "    print(\"Training the Model............\")\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)    \n",
    "    \n",
    "    \n",
    "    print(\"Features Computed for Testing data............\")\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "        \n",
    "    for testRow in testIndices:\n",
    "        X_test.append(X_input[testRow])\n",
    "        y_test.append(y_input[testRow])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test_list = y_test\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    \n",
    "    #Evaluate the model\n",
    "    loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "    predicted_results = model.predict_classes(X_test, batch_size=128)\n",
    "    \n",
    "    \n",
    "    #Get the score metrics\n",
    "    acc = accuracy_score(y_test, predicted_results)    \n",
    "    f1 = f1_score(y_test,predicted_results)\n",
    "    ras = roc_auc_score(y_test,predicted_results)\n",
    "    ps = precision_score(y_test,predicted_results)\n",
    "    recall = recall_score(y_test,predicted_results)\n",
    "    average_precision = average_precision_score(y_test,predicted_results)\n",
    "    \n",
    "    testAcc.append(acc)\n",
    "    testRAS.append(ras)\n",
    "    testF1.append(f1)\n",
    "    testPS.append(ps)\n",
    "    testRecall.append(recall)\n",
    "    testAvgPS.append(average_precision)\n",
    "    \n",
    "    print(acc)\n",
    "    print(f1)\n",
    "    print(ras)\n",
    "    print(ps)\n",
    "    print(recall)\n",
    "    print(average_precision)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average')\n",
    "print(np.mean(testAcc))\n",
    "print(np.mean(testF1))\n",
    "print(np.mean(testRAS))\n",
    "print(np.mean(testPS))\n",
    "print(np.mean(testRecall))\n",
    "print(np.mean(testAvgPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
