{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import utility as ut\n",
    "\n",
    "import features_final as f\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(filename,filenameWrite):\n",
    "    \n",
    "    cleaned_data = []\n",
    "    with open(filename,'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            #print len(row)\n",
    "            title = row[2]\n",
    "            description = row[6]\n",
    "            cleanedDescription = ut.cleanDescription(description)\n",
    "            cleanedTitle = ut.cleanText(title, False)\n",
    "            \n",
    "            # normalize price\n",
    "            price = float(row[7])\n",
    "            country = row[0]\n",
    "            newPrice = ut.normalizePrice(price, country)\n",
    "            \n",
    "            cleanedRow = [row[0],row[1],cleanedTitle,row[3],row[4],row[5],cleanedDescription, newPrice,row[8]]\n",
    "            cleaned_data.append(cleanedRow)\n",
    "\n",
    "    writer = csv.writer(open(filenameWrite, 'w'))\n",
    "    writer.writerows(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word Vectors............\n",
      "Loaded Word Vectors.............\n"
     ]
    }
   ],
   "source": [
    "w2v_model = f.loadWordVectors('google_news_word_vectors/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the text in the train data............\n"
     ]
    }
   ],
   "source": [
    "#Should be done only once\n",
    "\n",
    "print(\"Cleaning the text in the train data............\")\n",
    "clean('Data/training/data_train.csv','Data/training/data_train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Features............\n",
      "Features Computed............\n"
     ]
    }
   ],
   "source": [
    "#Pass the features that you want to test. The order of features are as given below\n",
    "#word2VecFlag \n",
    "#lengthAndBooleanFlag\n",
    "#tfidfLabelIntersectFlag\n",
    "#numericFlag\n",
    "#denseEntropySKUFlag\n",
    "\n",
    "print(\"Computing Features............\")\n",
    "X = f.extract_features(\"Data/training/data_train_clean.csv\",w2v_model,False,True,False,False,False)\n",
    "X_input = X.astype(np.float)\n",
    "\n",
    "print(\"Features Computed............\")\n",
    "\n",
    "y_input = np.loadtxt(\"data/training/clarity_train.labels\", dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the Feature Inputs\n",
    "\n",
    "X_std = (X_input - X_input.min(axis=0)) / (X_input.max(axis=0) - X_input.min(axis=0))\n",
    "X_input = X_std\n",
    "X_input = X_input[:,~np.all(np.isnan(X_input), axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pickle the files, load the pickled files\n",
    "#Use this only if you want to pickle the features and use it later, else don't run this cell\n",
    "\n",
    "import pickle\n",
    "\n",
    "#pickle.dump(X_input, open( \"X_input_numerical.p\", \"wb\" ))\n",
    "#pickle.dump(y_input, open( \"y_input_numerical.p\", \"wb\" ))\n",
    "\n",
    "#Load either the X_input_binary or X_input_numerical depending on the features to be tested\n",
    "#loaded_X_input = pickle.load( open( \"X_input_binary.p\", \"rb\" ) )\n",
    "#loaded_y_input = pickle.load( open( \"y_input_binary.p\", \"rb\" ) )\n",
    "\n",
    "#y_input = np.loadtxt(\"data/training/clarity_train.labels\", dtype=float)\n",
    "\n",
    "X_input = loaded_X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "y_new = list(y_input==1)\n",
    "#result = list(compress(range(len(y_new),y_new)))\n",
    "result_pos = [i for i,x in enumerate(y_new) if x]\n",
    "result_neg = [i for i,x in enumerate(y_new) if not x]\n",
    "\n",
    "X_input_pos = X_input[result_pos]\n",
    "y_input_pos = np.ones(len(X_input_pos));\n",
    "\n",
    "X_input_neg = X_input[result_neg]\n",
    "y_input_neg = np.zeros(len(X_input_neg));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kFoldResults = ut.splitKFold(X_input,y_input,5)\n",
    "\n",
    "F1 = []\n",
    "Acc = []\n",
    "Precision = []\n",
    "Roc = []\n",
    "Recall = []\n",
    "Avg_Prec = []\n",
    "\n",
    "\n",
    "for resultGenerator in kFoldResults:\n",
    "    trainIndices = resultGenerator[0]\n",
    "    testIndices = resultGenerator[1]\n",
    "    X_train = list()\n",
    "    y_train=list()\n",
    "    X_test=list()\n",
    "    y_test=list()\n",
    "    for trainRow in trainIndices:\n",
    "        X_train.append(X_input[trainRow])\n",
    "        y_train.append(y_input[trainRow])\n",
    "\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "        \n",
    "    print(\"Features Computed for Testing data............\")\n",
    "        \n",
    "    for testRow in testIndices:\n",
    "        X_test.append(X_input[testRow])\n",
    "        y_test.append(y_input[testRow])\n",
    "\n",
    "    y_bools = list(y_train==1)\n",
    "    train_split_pos = [i for i,x in enumerate(y_bools) if x]\n",
    "    train_split_neg = [i for i,x in enumerate(y_bools) if not x]\n",
    "\n",
    "    X_train_input_pos = X_input[train_split_pos]\n",
    "    y_train_input_pos = np.ones(len(train_split_pos));\n",
    "\n",
    "    X_train_input_neg = X_input[train_split_neg]\n",
    "    y_train_input_neg = np.zeros(len(train_split_neg));\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_train_input_pos.shape)\n",
    "    print(X_train_input_neg.shape)\n",
    "    \n",
    "    kFoldTrainingSplits = 6\n",
    "    kFoldTrainingData = ut.splitKFold(X_train_input_pos,y_train_input_pos,kFoldTrainingSplits)\n",
    "\n",
    "    models = list()\n",
    "    \n",
    "    for resultGenerator in kFoldTrainingData:\n",
    "        bigIndices = resultGenerator[0]\n",
    "        smallIndices = resultGenerator[1]\n",
    "        \n",
    "        X_train_input_small = list()\n",
    "        y_train_input_small = list()\n",
    "        for smallIndex in smallIndices:\n",
    "            X_train_input_small.append(X_input[smallIndex])\n",
    "            y_train_input_small.append(y_input[smallIndex])\n",
    "\n",
    "        X_train_input_small = np.asarray(X_train_input_small)\n",
    "        y_train_input_small = np.asarray(y_train_input_small)\n",
    "\n",
    "        X_train_new = np.concatenate((X_train_input_small,X_train_input_neg),axis=0);\n",
    "        y_train_new = np.concatenate((y_train_input_small,y_train_input_neg),axis=0);\n",
    "\n",
    "        p = np.random.permutation(len(X_train_new))\n",
    "        X_train_new = X_train_new[p]\n",
    "        y_train_new = y_train_new[p]\n",
    "    \n",
    "\n",
    "        # Model training\n",
    "        print(\"Training the Model............\")\n",
    "\n",
    "        #Replace with appropriate model, LogisticRegression, RandomForestClassifier for testing     \n",
    "        model = LogisticRegression()\n",
    "        \n",
    "        models.append(model)\n",
    "        models[len(models)-1].fit(X_train_new,y_train_new)\n",
    "\n",
    "        \n",
    "    print(\"Preciting labels from all classes............\")\n",
    "    y_predictions = list()\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        y_predictions.append(y_pred)\n",
    "\n",
    "    print(\"Finalzing test data classes............\")\n",
    "    y_predictions_sum = map(sum,zip(*y_predictions))\n",
    "    y_predictions_sum = np.asarray(y_predictions_sum)\n",
    "\n",
    "    y_predictions_bool = (y_predictions_sum >= (kFoldTrainingSplits/2))\n",
    "    y_predictions_bool = y_predictions_bool.astype(int)\n",
    "    y_predictions_classes = list((y_predictions_bool))\n",
    "    \n",
    "    \n",
    "    # Calculate the performance measures\n",
    "    acc = accuracy_score(y_test,y_predictions_classes)\n",
    "    f1 = f1_score(y_test,y_predictions_classes)\n",
    "    roc = roc_auc_score(y_test,y_predictions_classes)\n",
    "    precision = precision_score(y_test, y_predictions_classes)\n",
    "    recall = recall_score(y_test,y_predictions_classes)\n",
    "    avg_prec = average_precision_score(y_test, y_predictions_classes)\n",
    "\n",
    "    Acc.append(acc)\n",
    "    F1.append(f1)\n",
    "    Roc.append(roc)\n",
    "    Precision.append(precision)\n",
    "    Recall.append(recall)\n",
    "    Avg_Prec.append(avg_prec)\n",
    "\n",
    "    print acc\n",
    "    print f1 \n",
    "    print roc\n",
    "    print precision\n",
    "    print recall\n",
    "    print avg_prec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the average values\n",
    "print np.mean(Acc)\n",
    "print np.mean(Roc)\n",
    "print np.mean(Precision)\n",
    "print np.mean(F1)\n",
    "print np.mean(Recall)\n",
    "print np.mean(avg_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
